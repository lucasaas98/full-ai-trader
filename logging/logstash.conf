input {
  # Trading service logs via filebeat or direct file input
  beats {
    port => 5044
  }

  # Direct file input for development
  file {
    path => "/app/data/logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => multiline {
      pattern => "^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}"
      negate => true
      what => "previous"
    }
    tags => ["trading-system", "file-input"]
  }

  # Redis logs
  redis {
    host => "redis"
    port => 6379
    password => "Xo8uWxU1fmG0P1036pXysH2k4MTNhbmi"
    data_type => "list"
    key => "trading_logs"
    codec => "json"
    tags => ["trading-system", "redis-input"]
  }

  # Syslog input for system logs
  syslog {
    port => 5514
    tags => ["syslog"]
  }
}

filter {
  # Parse Python logging format from file input
  if "file-input" in [tags] {
    # Skip empty lines
    if [message] == "" {
      drop { }
    }

    grok {
      match => {
        "message" => "(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) - (?<logger_name>\S+) - (?<level>\w+) - (?<log_message>.*)"
      }
      tag_on_failure => ["_grokparsefailure_detailed"]
    }

    # Extract service name from file path
    if [path] {
      grok {
        match => {
          "path" => ".*/(?<service>[^/]+)\.log$"
        }
      }
    }

    # If no service extracted from path, try to extract from logger name or use "trading_system"
    if ![service] {
      if [logger_name] =~ /^src\./ {
        mutate {
          gsub => [ "logger_name", "^src\.", "" ]
          add_field => { "service" => "%{logger_name}" }
        }
      } else {
        mutate {
          add_field => { "service" => "trading_system" }
        }
      }
    }

    # Set event_type based on log content
    if [log_message] =~ /(?i)(trade|order|execution)/ {
      mutate { add_field => { "event_type" => "trade_execution" } }
    } else if [log_message] =~ /(?i)(signal|strategy)/ {
      mutate { add_field => { "event_type" => "strategy_signal" } }
    } else if [log_message] =~ /(?i)(risk|position|drawdown)/ {
      mutate { add_field => { "event_type" => "risk_check" } }
    } else if [log_message] =~ /(?i)(market|data|price|quote)/ {
      mutate { add_field => { "event_type" => "market_data" } }
    } else if [level] in ["ERROR", "CRITICAL"] {
      mutate { add_field => { "event_type" => "error" } }
    } else {
      mutate { add_field => { "event_type" => "general" } }
    }

    # Rename log_message to message for consistency
    mutate {
      rename => { "log_message" => "message" }
    }
  }

  # Parse timestamp (must come before removing the field)
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd HH:mm:ss.SSS", "yyyy-MM-dd HH:mm:ss,SSS" ]
      target => "@timestamp"
    }
    # Remove raw timestamp after parsing
    mutate {
      remove_field => [ "timestamp" ]
    }
  }

  # Parse service-specific logs
  if [service] {
    mutate {
      add_field => { "service_name" => "%{service}" }
    }
  }

  # Trading-specific parsing
  if "trading-system" in [tags] {
    # Parse trading events
    if [event_type] == "trade_execution" {
      mutate {
        add_tag => ["trade", "execution"]
      }

      # Convert string numbers to actual numbers
      if [quantity] {
        mutate {
          convert => { "quantity" => "float" }
        }
      }

      if [price] {
        mutate {
          convert => { "price" => "float" }
        }
      }

      if [value] {
        mutate {
          convert => { "value" => "float" }
        }
      }
    }

    # Parse strategy events
    if [event_type] == "strategy_signal" {
      mutate {
        add_tag => ["strategy", "signal"]
      }

      if [confidence] {
        mutate {
          convert => { "confidence" => "float" }
        }
      }
    }

    # Parse risk events
    if [event_type] == "risk_check" {
      mutate {
        add_tag => ["risk", "management"]
      }

      if [risk_score] {
        mutate {
          convert => { "risk_score" => "float" }
        }
      }

      if [position_size] {
        mutate {
          convert => { "position_size" => "float" }
        }
      }
    }

    # Parse market data events
    if [event_type] == "market_data" {
      mutate {
        add_tag => ["market", "data"]
      }

      if [bid] {
        mutate {
          convert => { "bid" => "float" }
        }
      }

      if [ask] {
        mutate {
          convert => { "ask" => "float" }
        }
      }

      if [volume] {
        mutate {
          convert => { "volume" => "integer" }
        }
      }
    }

    # Parse error events
    if [level] == "ERROR" or [level] == "CRITICAL" {
      mutate {
        add_tag => ["error", "critical"]
      }

      # Extract stack trace if present
      if [stack_trace] {
        mutate {
          add_field => { "error_stack" => "%{stack_trace}" }
        }
      }
    }

    # Parse performance metrics
    if [event_type] == "performance" {
      mutate {
        add_tag => ["performance", "metrics"]
      }

      if [duration_ms] {
        mutate {
          convert => { "duration_ms" => "float" }
        }
      }

      if [memory_usage] {
        mutate {
          convert => { "memory_usage" => "integer" }
        }
      }

      if [cpu_usage] {
        mutate {
          convert => { "cpu_usage" => "float" }
        }
      }
    }
  }

  # Parse HTTP logs
  if [http] {
    if [http][request] {
      mutate {
        add_tag => ["http", "request"]
      }
    }

    if [http][response] {
      mutate {
        add_tag => ["http", "response"]
      }

      if [http][response][status_code] {
        mutate {
          convert => { "[http][response][status_code]" => "integer" }
        }
      }

      if [http][response][duration_ms] {
        mutate {
          convert => { "[http][response][duration_ms]" => "float" }
        }
      }
    }
  }

  # Add environment information
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:development}"
      "log_processed_at" => "%{@timestamp}"
    }
  }

  # GeoIP enrichment for external IPs (if applicable)
  if [client_ip] and [client_ip] !~ /^(10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.)/ {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # Clean up unwanted fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "input", "log" ]
  }

  # Add correlation ID if not present
  if ![correlation_id] {
    uuid {
      target => "correlation_id"
    }
  }
}

output {
  # Main elasticsearch output
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "trading-logs-%{+YYYY.MM.dd}"
  }

  # Error logs to separate index
  if "error" in [tags] or [level] in ["ERROR", "CRITICAL", "FATAL"] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "trading-errors-%{+YYYY.MM.dd}"
    }
  }

  # Trading events to separate index
  if "trade" in [tags] or [event_type] == "trade_execution" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "trading-events-%{+YYYY.MM.dd}"
    }
  }

  # Performance metrics to separate index
  if "performance" in [tags] or [event_type] == "performance" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "trading-performance-%{+YYYY.MM.dd}"
    }
  }

  # Audit logs for compliance
  if [event_type] in ["trade_execution", "order_placement", "risk_violation", "strategy_change"] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "trading-audit-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (remove in production)
  if "${LOG_LEVEL:INFO}" == "DEBUG" {
    stdout {
      codec => rubydebug
    }
  }

  # Dead letter queue for failed parsing
  if "_grokparsefailure" in [tags] or "_dateparsefailure" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "trading-parse-failures-%{+YYYY.MM.dd}"
    }
  }
}
